{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lLHHTAZSuAdZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision.transforms import RandAugment\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WarmupCosineAnnealingLR(_LRScheduler):\n",
        "    def __init__(self, optimizer, warmup_epochs, max_epochs, last_epoch=-1):\n",
        "        self.warmup_epochs = warmup_epochs\n",
        "        self.max_epochs = max_epochs\n",
        "        super().__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        if self.last_epoch < self.warmup_epochs:\n",
        "            lr_scale = (self.last_epoch + 1) / self.warmup_epochs\n",
        "            return [base_lr * lr_scale for base_lr in self.base_lrs]\n",
        "        else:\n",
        "            progress = (self.last_epoch - self.warmup_epochs) / (self.max_epochs - self.warmup_epochs)\n",
        "            lr_scale = 0.5 * (1.0 + torch.cos(torch.tensor(progress * torch.pi)))\n",
        "            return [base_lr * lr_scale for base_lr in self.base_lrs]\n",
        "\n",
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, img_size=32, patch_size=8, in_channels=3, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.n_patches = (img_size // patch_size) ** 2\n",
        "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x)\n",
        "        x = x.flatten(2)\n",
        "        x = x.transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "class VisionTransformer(nn.Module):\n",
        "    # Using your desired scaled-up architecture\n",
        "    def __init__(self, img_size=32, patch_size=4, in_channels=3, embed_dim=256, n_classes=10, n_layers=8, n_heads=8, mlp_dim=512, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.patch_embedding = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, 1 + self.patch_embedding.n_patches, embed_dim))\n",
        "        self.pos_dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Transformer Encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim,\n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=mlp_dim,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "            # --- FIX 1: ADD THIS ARGUMENT FOR PRE-LAYER NORMALIZATION ---\n",
        "            norm_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "\n",
        "        # Classifier head\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.Linear(embed_dim, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embedding(x)\n",
        "        B, N, E = x.shape\n",
        "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x += self.pos_embed\n",
        "        x = self.pos_dropout(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        cls_output = x[:, 0]\n",
        "        return self.mlp_head(cls_output)\n"
      ],
      "metadata": {
        "id": "HIKdyF5DuPRh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(epochs=25, batch_size=64):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        RandAugment(num_ops=2, magnitude=9),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "    model = VisionTransformer().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # --- FIX 2: USE A SAFER LEARNING RATE ---\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "\n",
        "    scheduler = WarmupCosineAnnealingLR(optimizer, warmup_epochs=5, max_epochs=epochs)\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(\"Starting training with STABILIZED configuration...\")\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for data in trainloader:\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(trainloader):.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "        scheduler.step()\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"\\nFinished Training in {training_time:.2f}s\")\n",
        "\n",
        "    return model, training_time"
      ],
      "metadata": {
        "id": "d0SfUJwougfd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, batch_size=64):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    final_accuracy = 100 * correct / total\n",
        "    return final_accuracy"
      ],
      "metadata": {
        "id": "BwJlm2NKultI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    trained_model, total_training_time = train_model(epochs=25)\n",
        "    accuracy = evaluate_model(trained_model)\n",
        "\n",
        "    print(\"\\n--- Results ---\")\n",
        "    print(f\"Final Test Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Total Training Time: {total_training_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3io6R1Xz0Da",
        "outputId": "c8d9ee47-7f72-4877-eeec-90fc99e5355f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Starting training with STABILIZED configuration...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.9603, LR: 0.000060\n",
            "Epoch 2, Loss: 1.7416, LR: 0.000120\n",
            "Epoch 3, Loss: 1.5941, LR: 0.000180\n",
            "Epoch 4, Loss: 1.4878, LR: 0.000240\n",
            "Epoch 5, Loss: 1.4237, LR: 0.000300\n",
            "Epoch 6, Loss: 1.3570, LR: 0.000300\n",
            "Epoch 7, Loss: 1.3002, LR: 0.000298\n",
            "Epoch 8, Loss: 1.2480, LR: 0.000293\n",
            "Epoch 9, Loss: 1.2026, LR: 0.000284\n",
            "Epoch 10, Loss: 1.1572, LR: 0.000271\n",
            "Epoch 11, Loss: 1.1202, LR: 0.000256\n",
            "Epoch 12, Loss: 1.0815, LR: 0.000238\n",
            "Epoch 13, Loss: 1.0343, LR: 0.000218\n",
            "Epoch 14, Loss: 0.9981, LR: 0.000196\n",
            "Epoch 15, Loss: 0.9607, LR: 0.000173\n",
            "Epoch 16, Loss: 0.9194, LR: 0.000150\n",
            "Epoch 17, Loss: 0.8886, LR: 0.000127\n",
            "Epoch 18, Loss: 0.8598, LR: 0.000104\n",
            "Epoch 19, Loss: 0.8276, LR: 0.000082\n",
            "Epoch 20, Loss: 0.8019, LR: 0.000062\n",
            "Epoch 21, Loss: 0.7802, LR: 0.000044\n",
            "Epoch 22, Loss: 0.7603, LR: 0.000029\n",
            "Epoch 23, Loss: 0.7508, LR: 0.000016\n",
            "Epoch 24, Loss: 0.7467, LR: 0.000007\n",
            "Epoch 25, Loss: 0.7255, LR: 0.000002\n",
            "\n",
            "Finished Training in 1498.44s\n",
            "\n",
            "--- Results ---\n",
            "Final Test Accuracy: 78.62%\n",
            "Total Training Time: 1498.44 seconds\n"
          ]
        }
      ]
    }
  ]
}